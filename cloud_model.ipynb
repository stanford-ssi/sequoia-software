{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c86a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from osgeo import gdal\n",
    "assets = list(glob(\"BC/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "416bbed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC/LC81220422014096LGN00/LC81220422014096LGN00_fixedmask.tif\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received a NULL pointer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-50ba27ef3e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GTiff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mTranslate\u001b[0;34m(destName, srcDS, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0msrcDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrcDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTranslateInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrcDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m def WarpOptions(options=None, format=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mTranslateInternal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4569\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mTranslateInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4570\u001b[0m     \u001b[0;34m\"\"\"TranslateInternal(char const * dest, Dataset dataset, GDALTranslateOptions translateOptions, GDALProgressFunc callback=0, void * callback_data=None) -> Dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4571\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTranslateInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4572\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGDALWarpAppOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4573\u001b[0m     \u001b[0;34m\"\"\"Proxy of C++ GDALWarpAppOptions class.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Received a NULL pointer."
     ]
    }
   ],
   "source": [
    "ds = []\n",
    "for asset in assets:\n",
    "    paths = Path(asset).glob('*')\n",
    "    blue, green, red, mask = None, None, None, None\n",
    "\n",
    "    for path in paths:\n",
    "        path = str(path)\n",
    "        if 'B2' in path: blue = path\n",
    "        elif 'B3' in path: green = path\n",
    "        elif 'B4' in path: red = path\n",
    "        elif 'fixedmask.img' in path: \n",
    "            mask = path.replace('.img', '.TIF')\n",
    "            print(mask)\n",
    "            input = gdal.Translate(mask, gdal.Open(path), format=\"GTiff\")\n",
    "            input = None \n",
    "\n",
    "    images = (red, green, blue, mask)\n",
    "    # some times download gets corrupted, if so, throw that row away\n",
    "    if None in images: pass\n",
    "    else: ds.append(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c520a3ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Received a NULL pointer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-8cfb7592f682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello.TIF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BC/LC80160502014041LGN00/LC80160502014041LGN00_fixedmask.img'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GTiff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mTranslate\u001b[0;34m(destName, srcDS, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0msrcDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrcDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTranslateInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrcDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m def WarpOptions(options=None, format=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mTranslateInternal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4569\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mTranslateInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4570\u001b[0m     \u001b[0;34m\"\"\"TranslateInternal(char const * dest, Dataset dataset, GDALTranslateOptions translateOptions, GDALProgressFunc callback=0, void * callback_data=None) -> Dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4571\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTranslateInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4572\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGDALWarpAppOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4573\u001b[0m     \u001b[0;34m\"\"\"Proxy of C++ GDALWarpAppOptions class.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Received a NULL pointer."
     ]
    }
   ],
   "source": [
    "input = gdal.Translate('hello.TIF', gdal.Open('BC/LC80160502014041LGN00/LC80160502014041LGN00_fixedmask.img'), format=\"GTiff\")\n",
    "input = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def read_img_and_mask(files):\n",
    "    # read img at specified path\n",
    "    r, g, b, mask = files[0], files[1], files[2], files[3]\n",
    "\n",
    "    # read in each band and the mask as tiff files. \n",
    "    # tf reads this as RGBE, but, each is essentially single band\n",
    "    # (including the mask), not the 4 bands tf expects\n",
    "    # so strip out 'R', because 'R' 'G' 'B' bands are all (verifiably) equal. \n",
    "    # E is meaningless (all 255), so we dont use it\n",
    "    r, g, b, mask = map(\n",
    "        lambda x: tfio.experimental.image.decode_tiff(tf.io.read_file(x))[:, :, 0], \n",
    "        [r, g, b, mask])\n",
    "    img = tf.experimental.numpy.dstack((r, g, b))\n",
    "\n",
    "    # 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80420082013220LGN00.tar.gz'\n",
    "    # the mask values correspond to the following classes:\n",
    "    # Fill 0, Cloud Shadow 64, Clear 128, Thin Cloud 192, Cloud 255\n",
    "    thin_cloud = tf.where(mask == 192, True, False)\n",
    "    cloud = tf.where(mask == 255, True, False)\n",
    "    mask = tf.math.logical_or(thin_cloud, cloud)\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample_crop(img, mask, h, w, n):\n",
    "  # take n random crops of size h, w from an image and its mask \n",
    "  # stack mask and image s.t. we crop both at the same time\n",
    "  img_and_mask = tf.experimental.numpy.dstack((img, mask))\n",
    "  crops = [tf.image.random_crop(img_and_mask, (h, w, 4)) for i in range(n)]\n",
    "  # convert the n stacked, cropped images into a dataset\n",
    "  crops = tf.stack(crops)\n",
    "  crops = tf.data.Dataset.from_tensor_slices(crops)\n",
    "  return crops\n",
    "\n",
    "\n",
    "\n",
    "def build_unet_segmentation_model(h, w, c):\n",
    "    # UNet Semantic Segmentation Architecture\n",
    "\n",
    "    # Build the model\n",
    "    inputs = layers.Input((h, w, c))\n",
    "    s = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(s)\n",
    "    c1 = layers.Dropout(0.1)(c1)\n",
    "    c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Dropout(0.1)(c2)\n",
    "    c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Dropout(0.2)(c3)\n",
    "    c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Dropout(0.2)(c4)\n",
    "    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Dropout(0.3)(c5)\n",
    "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    #Expansive path \n",
    "    u6 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Dropout(0.2)(c6)\n",
    "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Dropout(0.2)(c7)\n",
    "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Dropout(0.1)(c8)\n",
    "    c8 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1], axis=3)\n",
    "    c9 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Dropout(0.1)(c9)\n",
    "    c9 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def weight_clouds_more(image, mask, ratio=[1.0, 3.0]):\n",
    "  # normalize the weights to sum to 1\n",
    "  class_weights = tf.constant(ratio)\n",
    "  class_weights = class_weights/tf.reduce_sum(class_weights)\n",
    "\n",
    "  # make another mask, but one that has weights for every pixel\n",
    "  weights = tf.gather(class_weights, indices=tf.cast(mask, tf.int32))\n",
    "  return image, mask, weights\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # save the links for each of the 96 asset scenes\n",
    "    links = get_asset_links()\n",
    "    asset_links = write_links_to_file(links, fname='links.txt'):\n",
    "    # download & extract assets (BE CAREFUL, TUNE HOW PARALLEL YOU WANT THIS)\n",
    "    assets_dir = download_assets(asset_links, download_directory='assets')\n",
    "    assets = extract(in_dir=assets_dir, out_dir=assets_dir)\n",
    "    # make dataset consisting of the bands and mask for each asset\n",
    "    ds = make_ds_from_assets(assets)\n",
    "\n",
    "    # convenience args for parallel preprocessing\n",
    "    parallelize = dict(num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    \n",
    "    # read in images and mask .TIF files\n",
    "    ds = ds.map(read_img_and_mask, **parallelize)\n",
    "    CARDINALITY = ds.cardinality()\n",
    "    \n",
    "    # take n random crops of size h, w\n",
    "    n, h, w, c = 20, 128, 128, 3\n",
    "    ds = ds.interleave(lambda img, mask: sample_crop(img, mask, h, w, n), **parallelize)\n",
    "    # unstack the stacked image + mask into a tuple of image, mask\n",
    "    ds = ds.map(lambda x: (x[:, :, 0:3], x[:, :, 3]), **parallelize)\n",
    "    CARDINALITY *= n\n",
    "    ds = ds.apply(tf.data.experimental.assert_cardinality(CARDINALITY))\n",
    "\n",
    "    # weight clouds more in loss function, because high cost of false negatives\n",
    "    ds = ds.map(weight_clouds_more, **parallelize)\n",
    "\n",
    "    # shuffle, then construct 80-20 train-test split\n",
    "    # use a batch size of 32, and \n",
    "    # prefetch to reduce time to max of preprocessing and ML, rather than sum\n",
    "    ds = ds.shuffle(buffer_size=CARDINALITY)\n",
    "    test_ds = ds.take(CARDINALITY // 5).prefetch(tf.data.AUTOTUNE).batch(32)\n",
    "    train_ds = ds.skip(CARDINALITY // 5).prefetch(tf.data.AUTOTUNE).batch(32)\n",
    "\n",
    "    # UNet Semantic Segmentation Architecture\n",
    "    # see original paper here: https://arxiv.org/abs/1505.04597\n",
    "    model = build_unet_segmentation_model(h, w, c)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # train & save the best model from training\n",
    "    os.system('mkdir saved_model') \n",
    "    history = model.fit(\n",
    "      train_ds,\n",
    "      validation_data=test_ds,\n",
    "      epochs=50,\n",
    "      callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
    "                    'saved_model/cloud_model_checkpoint',\n",
    "                     monitor=\"val_loss\",\n",
    "                     save_best_only=True,\n",
    "                     save_freq=\"epoch\")])\n",
    "    \n",
    "    # done! save model to disk\n",
    "    print(model.evaluate(test_ds))\n",
    "    model.save('saved_model/cloud_model_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8232a0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969071b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
