{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sequoia_cloud_models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yC6pYiVSV7RQ",
        "9mRJZhxDMyYT",
        "QIHilPvZNUns",
        "ObgIDZS7613A"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC6pYiVSV7RQ"
      },
      "source": [
        "## General Info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRBNDY08Nn9L"
      },
      "source": [
        "This is the dataset currently loaded:\n",
        "\n",
        "1. [Sparcs Dataset ~2GB](https://www.usgs.gov/core-science-systems/nli/landsat/spatial-procedures-automated-removal-cloud-and-shadow-sparcs)\n",
        "\n",
        "\n",
        "These are some other options we have:\n",
        "\n",
        "1. [Landsat Validation Data ~100GB](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-8-cloud-cover-assessment-validation-data?qt-science_support_page_related_con=1#qt-science_support_page_related_con)\n",
        "\n",
        "2. [Kaggle Dataset ~20GB](https://www.kaggle.com/sorour/95cloud-cloud-segmentation-on-satellite-images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mRJZhxDMyYT"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "154PdSSENsoF"
      },
      "source": [
        "Download the SPARCS dataset of images, which for each image contains:\n",
        "  1. satellite tiff file (format w/ multiple color bands besides RGB)\n",
        "  2. txt metadata about the image\n",
        "  3. a satellite image png\n",
        "  4. a satellite mask png (with colors representing masks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33GbPU6irqt5"
      },
      "source": [
        "# download SPARCS dataset\n",
        "!wget https://landsat.usgs.gov/cloud-validation/sparcs/l8cloudmasks.zip\n",
        "# unzip the dataset\n",
        "!unzip l8cloudmasks.zip\n",
        "# delete zipped folder\n",
        "!rm -rf l8cloudmasks.zip\n",
        "# rename file \n",
        "!mv sending clouds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPFyp0R0K_bl"
      },
      "source": [
        "# where the images are stored \n",
        "dataset_path = '/content/clouds'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIHilPvZNUns"
      },
      "source": [
        "## Read Data into Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhNeBSAF8GWL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urgMxtOE4mGW"
      },
      "source": [
        "# Given an image path, read in both the image and its mask\n",
        "# by loading img and mask as stacked tensor i.e. (2, w, h, d) #\n",
        "@tf.function\n",
        "def read_img_and_mask(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"photo\", \"mask\")\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "\n",
        "    return tf.stack([img, mask])"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs4t98kd8JlM"
      },
      "source": [
        "# creates a dataset consisting of image file paths\n",
        "ds = tf.data.Dataset.list_files(dataset_path + \"/*photo.png\")\n",
        "# read in each image and its mask using those file paths \n",
        "ds = ds.map(read_img_and_mask)\n",
        "\n",
        "CARDINALITY = ds.cardinality()"
      ],
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFL3wo9zN6bD"
      },
      "source": [
        "# take n random crops of an image and its mask\n",
        "@tf.function\n",
        "def sample_crop(dp, w, h, n):\n",
        "  crops = [tf.image.random_crop(dp, (2, w, h, 3)) for i in range(n)]\n",
        "  crops = tf.stack(crops)\n",
        "  crops = tf.data.Dataset.from_tensor_slices(crops)\n",
        "  return crops"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QX2p1tZ287"
      },
      "source": [
        "# randomly crop each img (and its mask) several times\n",
        "n, w, h = 5, 128, 128\n",
        "ds = ds.flat_map(lambda dp: sample_crop(dp, w, h, n))\n",
        "ds.take(1)\n",
        "\n",
        "# tf doesn't know cardinality after flatmap, so we help it out\n",
        "CARDINALITY *= n\n",
        "ds = ds.apply(tf.data.experimental.assert_cardinality(CARDINALITY))"
      ],
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4unn-fLDnDKM"
      },
      "source": [
        "@tf.function\n",
        "def normalize(dp):\n",
        "  img = tf.cast(dp['img'], tf.float32) / 255.0\n",
        "  # convert to single channel\n",
        "  mask = tf.image.rgb_to_grayscale(dp['mask'])\n",
        "  # now, all pixels are 0, 127, or 255, convert to labels 0, 1, 2\n",
        "  mask = tf.math.floordiv(mask, 127)\n",
        "  return {'img': img, 'mask': mask}\n",
        "\n",
        "@tf.function\n",
        "def prepare(dp):\n",
        "  img, mask = tf.unstack(dp)\n",
        "  return {'img': img, 'mask': mask}"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2K983q_pLXR"
      },
      "source": [
        "# normalize and put in correct format\n",
        "ds = ds.map(prepare)\n",
        "ds = ds.map(normalize)"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOqZRQZRqvnb"
      },
      "source": [
        "# random shuffle\n",
        "ds.shuffle(buffer_size=CARDINALITY)\n",
        "# split into train and test\n",
        "test_ds = ds.take(CARDINALITY // 5)\n",
        "train_ds = ds.skip(CARDINALITY // 5)"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObgIDZS7613A"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6JUs0fz7fX_"
      },
      "source": [
        "Refer to [Tensorflow Image Segmentation](https://www.tensorflow.org/tutorials/images/segmentation) for next steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Sz_YmO67sE"
      },
      "source": [
        "# we have two datasets, train_ds & test_ds\n",
        "# each is a dataset of {'img': img, 'mask': mask} dicts\n",
        "# where img is a tensor of shape (128, 128, 3)\n",
        "# and mask is a tensor of shape (128, 128, 1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}