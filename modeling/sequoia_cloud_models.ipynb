{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sequoia_cloud_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRBNDY08Nn9L"
      },
      "source": [
        "This is the dataset currently loaded:\n",
        "\n",
        "1. [Sparcs Dataset ~2GB](https://www.usgs.gov/core-science-systems/nli/landsat/spatial-procedures-automated-removal-cloud-and-shadow-sparcs)\n",
        "  1. satellite tiff file (format w/ multiple channels, i.e. infrared as well as RGB)\n",
        "  2. txt metadata about the image\n",
        "  3. a satellite image png\n",
        "  4. a satellite mask png (with colors representing masks)\n",
        "\n",
        "These are some other options we have:\n",
        "\n",
        "1. [Landsat Validation Data ~100GB](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-8-cloud-cover-assessment-validation-data?qt-science_support_page_related_con=1#qt-science_support_page_related_con)\n",
        "\n",
        "2. [Kaggle Dataset ~20GB](https://www.kaggle.com/sorour/95cloud-cloud-segmentation-on-satellite-images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhNeBSAF8GWL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import Sequential, layers, preprocessing \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# convenience key-word args to parallel process\n",
        "parallel_map_kwargs = dict(\n",
        "  num_parallel_calls=tf.data.AUTOTUNE,\n",
        "  deterministic=False)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1fJ6-u94ke"
      },
      "source": [
        "#### DOWNLOAD THE SPARCS DATASET ####\n",
        "def download(data_url):\n",
        "  dl_manager = tfds.download.DownloadManager(download_dir='junk', extract_dir='/content/clouds')\n",
        "  dataset_path = dl_manager.download_and_extract(data_url)\n",
        "  dataset_path += '/sending' # weird USGS quirks\n",
        "  return dataset_path\n",
        "\n",
        "# creates a dataset consisting of image file paths\n",
        "SPARCS_DATA_URL = 'https://landsat.usgs.gov/cloud-validation/sparcs/l8cloudmasks.zip'\n",
        "dataset_path = download(SPARCS_DATA_URL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdQK0QQgrHhP"
      },
      "source": [
        "dataset_path = '/content/clouds/ZIP.landsa.usgs.gov_cloud-valida_sparcs_l8clouN5mc1TWFYYYxSYyyS6tlUpIEWUINgMuHXOHfkoDGofw.zip/sending'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc3OLjwQYJx1"
      },
      "source": [
        "#### READ IMAGE & MASK TO DATASET ####\n",
        "def read_img_and_mask(img_path: tf.Tensor):\n",
        "    # read img at specified path\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img)\n",
        "    #img = tf.image.rgb_to_grayscale(img)\n",
        "\n",
        "    # read corresponding mask (whose path replaces 'photo' w/ 'mask')\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"photo\", \"mask\")\n",
        "    mask = Image.open(mask_path.numpy())\n",
        "    mask = tf.convert_to_tensor(np.array(mask))\n",
        "    #mask = tf.where(mask == 5, tf.ones_like(mask), tf.zeros_like(mask))\n",
        "\n",
        "    # tuple of img and mask\n",
        "    return img, mask"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZL1HTs2Rjfd"
      },
      "source": [
        "ds = tf.data.Dataset.list_files(dataset_path + \"/*photo.png\")\n",
        "# read in each image and its mask using those file paths \n",
        "ds = ds.map(lambda x: tf.py_function(func=read_img_and_mask,\n",
        "                                     inp=[x], \n",
        "                                     Tout=(tf.uint8, tf.uint8)\n",
        "                                     ), **parallel_map_kwargs)\n",
        "# size of dataset\n",
        "CARDINALITY = ds.cardinality()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFL3wo9zN6bD"
      },
      "source": [
        "# take n random crops of an image and its mask\n",
        "@tf.function\n",
        "def sample_crop(img, mask, w, h, n):\n",
        "  img_and_mask = tf.experimental.numpy.dstack((img, mask))\n",
        "  crops = [tf.image.random_crop(img_and_mask, (w, h, 4)) for i in range(n)]\n",
        "  crops = tf.stack(crops)\n",
        "  crops = tf.data.Dataset.from_tensor_slices(crops)\n",
        "  return crops"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QX2p1tZ287"
      },
      "source": [
        "# randomly crop each img (and its mask) several times\n",
        "n, w, h = 5, 64, 64\n",
        "ds = ds.interleave(lambda img, mask: sample_crop(img, mask, w, h, n), **parallel_map_kwargs)\n",
        "\n",
        "# tf doesn't know cardinality after interleave, so we help it out\n",
        "CARDINALITY *= n\n",
        "ds = ds.apply(tf.data.experimental.assert_cardinality(CARDINALITY))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2K983q_pLXR"
      },
      "source": [
        "# represent as tuple of img, mask rather than mask stacked beneath image\n",
        "ds = ds.map(lambda x: (x[:, :, 0:3], x[:, :, 3]), **parallel_map_kwargs)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2cGpL3dwKI2"
      },
      "source": [
        "@tf.function\n",
        "def cloud_score(img, mask):  \n",
        "  # cloud mask is 5\n",
        "  clouds = tf.math.count_nonzero(mask == 5)\n",
        "  cloud_score = clouds / tf.size(mask, out_type=tf.int64)\n",
        "  cloud_score = cloud_score > 0.5\n",
        "  return img, cloud_score\n",
        "\n",
        "ds = ds.map(cloud_score, **parallel_map_kwargs)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOqZRQZRqvnb"
      },
      "source": [
        "# random shuffle\n",
        "ds.shuffle(buffer_size=CARDINALITY)\n",
        "\n",
        "# after shuffle, first 20% are test, last 80% are train\n",
        "test_ds = ds.take(CARDINALITY // 5)\n",
        "train_ds = ds.skip(CARDINALITY // 5)\n",
        "\n",
        "test_ds = test_ds.prefetch(tf.data.AUTOTUNE).batch(32)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE).batch(32)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpAnBqJRls-w"
      },
      "source": [
        "num_classes = 2\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(64, 64, 3)),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64 * 64, activation='relu'), \n",
        "  layers.Dense(64 * 64, activation='relu'), \n",
        "  layers.Dense(64 * 64), \n",
        "  layers.Dense(num_classes) \n",
        "])"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZmrkOGSqGNM"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI7H8LH-BDKZ"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpo_eFmCqJdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3523b7b1-c6bd-463d-c7fb-9cea91f01e8b"
      },
      "source": [
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=test_ds,\n",
        "  epochs=10,\n",
        "  callbacks=[callback]\n",
        ")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 2.4493 - accuracy: 0.6572 - val_loss: 2.6192 - val_accuracy: 0.8375\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.5019 - accuracy: 0.8448 - val_loss: 2.8207 - val_accuracy: 0.8250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.9762 - accuracy: 0.8153 - val_loss: 3.8280 - val_accuracy: 0.7625\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.1253 - accuracy: 0.8681 - val_loss: 2.8207 - val_accuracy: 0.8250\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 4.2712 - accuracy: 0.7350 - val_loss: 1.6118 - val_accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6667 - accuracy: 0.8346 - val_loss: 3.2236 - val_accuracy: 0.8000\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6730 - accuracy: 0.8342 - val_loss: 3.0221 - val_accuracy: 0.8125\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.2533 - accuracy: 0.8602 - val_loss: 2.0148 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.6741 - accuracy: 0.8341 - val_loss: 3.0221 - val_accuracy: 0.8125\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 2.3248 - accuracy: 0.8558 - val_loss: 2.2162 - val_accuracy: 0.8625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}