{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sequoia_cloud_models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yC6pYiVSV7RQ",
        "9mRJZhxDMyYT",
        "QIHilPvZNUns",
        "ObgIDZS7613A"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC6pYiVSV7RQ"
      },
      "source": [
        "## General Info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRBNDY08Nn9L"
      },
      "source": [
        "This is the dataset currently loaded:\n",
        "\n",
        "1. [Sparcs Dataset ~2GB](https://www.usgs.gov/core-science-systems/nli/landsat/spatial-procedures-automated-removal-cloud-and-shadow-sparcs)\n",
        "\n",
        "\n",
        "These are some other options we have:\n",
        "\n",
        "1. [Landsat Validation Data ~100GB](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-8-cloud-cover-assessment-validation-data?qt-science_support_page_related_con=1#qt-science_support_page_related_con)\n",
        "\n",
        "2. [Kaggle Dataset ~20GB](https://www.kaggle.com/sorour/95cloud-cloud-segmentation-on-satellite-images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mRJZhxDMyYT"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "154PdSSENsoF"
      },
      "source": [
        "Download the SPARCS dataset of images, which for each image contains:\n",
        "  1. satellite tiff file (format w/ multiple color bands besides RGB)\n",
        "  2. txt metadata about the image\n",
        "  3. a satellite image png\n",
        "  4. a satellite mask png (with colors representing masks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhNeBSAF8GWL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1fJ6-u94ke"
      },
      "source": [
        "# download the SPARCS dataset\n",
        "dl_manager = tfds.download.DownloadManager(download_dir='junk', extract_dir='/content/clouds')\n",
        "data_url = 'https://landsat.usgs.gov/cloud-validation/sparcs/l8cloudmasks.zip'\n",
        "dataset_path = dl_manager.download_and_extract(data_url)\n",
        "dataset_path += '/sending' # weird USGS quirks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIHilPvZNUns"
      },
      "source": [
        "## Read Data into Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGOvPeEa39e4"
      },
      "source": [
        "# convenience kwargs\n",
        "parallel_map_kwargs = dict(\n",
        "  num_parallel_calls=tf.data.AUTOTUNE,\n",
        "  deterministic=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urgMxtOE4mGW"
      },
      "source": [
        "# Given an image path, read in both the image and its mask\n",
        "# by loading img and mask as a stacked tensor i.e. (2, w, h, d) #\n",
        "@tf.function\n",
        "def read_img_and_mask(img_path):\n",
        "    # read img at specified path\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    # read corresponding mask (whose path replaces 'photo' w/ 'mask')\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"photo\", \"mask\")\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "    return tf.stack([img, mask])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs4t98kd8JlM"
      },
      "source": [
        "# creates a dataset consisting of image file paths\n",
        "ds = tf.data.Dataset.list_files(dataset_path + \"/*photo.png\")\n",
        "# read in each image and its mask using those file paths \n",
        "ds = ds.map(read_img_and_mask, **parallel_map_kwargs)\n",
        "\n",
        "CARDINALITY = ds.cardinality()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFL3wo9zN6bD"
      },
      "source": [
        "# take n random crops of an image and its mask\n",
        "@tf.function\n",
        "def sample_crop(dp, w, h, n):\n",
        "  crops = [tf.image.random_crop(dp, (2, w, h, 3)) for i in range(n)]\n",
        "  crops = tf.stack(crops)\n",
        "  crops = tf.data.Dataset.from_tensor_slices(crops)\n",
        "  return crops"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QX2p1tZ287"
      },
      "source": [
        "# randomly crop each img (and its mask) several times\n",
        "n, w, h = 5, 128, 128\n",
        "ds = ds.interleave(lambda dp: sample_crop(dp, w, h, n), **parallel_map_kwargs)\n",
        "ds.take(1)\n",
        "\n",
        "# tf doesn't know cardinality after flatmap, so we help it out\n",
        "CARDINALITY *= n\n",
        "ds = ds.apply(tf.data.experimental.assert_cardinality(CARDINALITY))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4unn-fLDnDKM"
      },
      "source": [
        "@tf.function\n",
        "def normalize(dp):\n",
        "  img = tf.cast(dp['img'], tf.float32) / 255.0\n",
        "  # convert to single channel\n",
        "  mask = tf.image.rgb_to_grayscale(dp['mask'])\n",
        "  # now that all pixels are 0, 127, or 255, convert to labels 0, 1, 2\n",
        "  mask = tf.math.floordiv(mask, 127)\n",
        "  return {'img': img, 'mask': mask}\n",
        "\n",
        "@tf.function\n",
        "def prepare(dp):\n",
        "  img, mask = tf.unstack(dp)\n",
        "  return {'img': img, 'mask': mask}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2K983q_pLXR"
      },
      "source": [
        "# normalize and put in correct format\n",
        "ds = ds.map(prepare, **parallel_map_kwargs)\n",
        "ds = ds.map(normalize, **parallel_map_kwargs)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOqZRQZRqvnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdefb712-ad3f-4943-f837-3c34580f6f51"
      },
      "source": [
        "# random shuffle\n",
        "ds.shuffle(buffer_size=CARDINALITY)\n",
        "# split into train and test\n",
        "test_ds = ds.take(CARDINALITY // 5)\n",
        "train_ds = ds.skip(CARDINALITY // 5)\n",
        "# prefetch for optimal performance\n",
        "train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "test_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: {img: (128, 128, 3), mask: (128, 128, 1)}, types: {img: tf.float32, mask: tf.uint8}>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObgIDZS7613A"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6JUs0fz7fX_"
      },
      "source": [
        "Refer to [Tensorflow Image Segmentation](https://www.tensorflow.org/tutorials/images/segmentation) for next steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Sz_YmO67sE"
      },
      "source": [
        "# we have two datasets, train_ds & test_ds\n",
        "# each is a dataset of {'img': img, 'mask': mask} dicts\n",
        "# where img is a tensor of shape (128, 128, 3)\n",
        "# and mask is a tensor of shape (128, 128, 1)"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}