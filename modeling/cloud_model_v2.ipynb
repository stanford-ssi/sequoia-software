{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequoia V2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRBNDY08Nn9L"
      },
      "source": [
        "Possible Datasets: (landsat loaded rn)\n",
        "\n",
        "1. [Sparcs Dataset ~2GB](https://www.usgs.gov/core-science-systems/nli/landsat/spatial-procedures-automated-removal-cloud-and-shadow-sparcs)\n",
        "\n",
        "2. [Landsat Validation Data ~100GB](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-8-cloud-cover-assessment-validation-data?qt-science_support_page_related_con=1#qt-science_support_page_related_con)\n",
        "\n",
        "3. [Kaggle Dataset ~20GB](https://www.kaggle.com/sorour/95cloud-cloud-segmentation-on-satellite-images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y-esOjzYZqy"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ANpoughmMI",
        "outputId": "8cacf7f5-75a1-4ff3-da9a-760646788cfe"
      },
      "source": [
        "# landsat 8 data, should be 96 files of the following form:\n",
        "# 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80420082013220LGN00.tar.gz'\n",
        "\n",
        "url = 'https://landsat.usgs.gov/landsat-8-cloud-cover-assessment-validation-data'\n",
        "reqs = requests.get(url)\n",
        "soup = BeautifulSoup(reqs.text, 'html.parser')\n",
        " \n",
        "links = []\n",
        "for link in soup.find_all('a'):\n",
        "    link = link.get('href')\n",
        "    criterion1 = 'https://landsat.usgs.gov/cloud-validation/cca_l8/'\n",
        "    criterion2 = 'tar.gz'\n",
        "    if link is not None and criterion1 in link and criterion2 in link:\n",
        "      links.append(link)\n",
        "\n",
        "print(len(links), links)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96 ['https://landsat.usgs.gov/cloud-validation/cca_l8/LC80420082013220LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80500092014231LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80530022014156LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81330312013202LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81360302014162LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81390292014135LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81550082014263LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81570452014213LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81640502013179LGN01.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81750432013144LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81930452013126LGN01.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81990402014267LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80070662014234LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80160502014041LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80200462014005LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80500172014247LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81170272014189LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81310182013108LGN01.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81330182013186LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81720192013331LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81750622013304LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81800662014230LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC82290572014141LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC82310592014139LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80290292014132LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80290372013257LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80980712014024LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81220312014208LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81220422014096LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81320352013243LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81440462014250LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81490432014141LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81510262014139LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81750512013208LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81820302014180LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC82020522013141LGN01.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80010732013109LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80320382013278LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80350192014190LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80630152013207LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80670172014206LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80750172013163LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80760182013170LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80980762014216LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81020802014100LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81490122013218LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81590362014051LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81600462013215LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80010112014080LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80060102014147LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80211222013361LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80250022014232LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80441162013330LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80841202014309LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81001082014022LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81321192014054LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC82001192013335LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC82171112014297LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC82271192014287LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC82320072014226LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80150312014226LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80170312013157LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80410372013357LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80460282014171LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80640452014041LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81180382014244LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81620432014072LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81660432014020LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81770262013254LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81920192013103LGN01.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81940222013245LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81970242013218LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80120552013202LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80180082014215LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80210072014236LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80430122014214LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80650182013237LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81040622014066LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81130632014241LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81240462014238LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81620582014104LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81660032014196LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81910182013240LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC82150712013152LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80310202013223LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80340192014167LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81010142014189LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81020152014036LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81030162014107LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81070152013260LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81080162013171LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81080182014238LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81460162014168LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81500152013225LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81580172013201LGN00.tar.gz', 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC81750732014035LGN00.tar.gz']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1fJ6-u94ke"
      },
      "source": [
        "# #### DOWNLOAD THE LANDDSAT 8 DATASET ####\n",
        "def download(data_url):\n",
        "  dl_manager = tfds.download.DownloadManager(download_dir='/tmp/junk/', extract_dir='/content/clouds')\n",
        "  dataset_path = dl_manager.download_and_extract(data_url)\n",
        "  return dataset_path\n",
        "\n",
        "# creates a dataset consisting of image file paths\n",
        "cloud_paths = download(links)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrOuoqZsk5XC"
      },
      "source": [
        "# bands 2,3,4 are BGR (in that order)\n",
        "# according to https://www.usgs.gov/faqs/what-are-band-designations-landsat-satellites?qt-news_science_products=0#qt-news_science_products\n",
        "\n",
        "ds = []\n",
        "for asset in cloud_paths:\n",
        "  blue, green, red, mask = None, None, None, None\n",
        "  paths = [str(path) for path in Path(asset).rglob('*_*')]\n",
        "  for path in paths:\n",
        "    if 'B2' in path: blue = path\n",
        "    elif 'B3' in path: green = path\n",
        "    elif 'B4' in path: red = path\n",
        "    elif 'fixedmask.img' in path: \n",
        "      mask = path.replace('.img', '.TIF')\n",
        "      # the usgs stored it in wack format, we have to call a command line\n",
        "      # utility to convert from the mask file from .img to .TIF\n",
        "      !gdal_translate -of GTiff {path + \" \" + mask}\n",
        "\n",
        "  images = (red, green, blue, mask)\n",
        "  # some times download gets corrupted, if so, throw that row away\n",
        "  if None in images: pass\n",
        "  else: ds.append(images)\n",
        "\n",
        "# dataset where each row is a tuple of \n",
        "# paths for red, green, blue, and mask\n",
        "# where each path points to a .TIF file\n",
        "ds = tf.data.Dataset.from_tensor_slices(ds)\n",
        "print(ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc3OLjwQYJx1"
      },
      "source": [
        "# convenience key-word args to parallel process\n",
        "parallelize = dict(\n",
        "  num_parallel_calls=tf.data.AUTOTUNE,\n",
        "  deterministic=False)\n",
        "\n",
        "# 'https://landsat.usgs.gov/cloud-validation/cca_l8/LC80420082013220LGN00.tar.gz'\n",
        "# the mask values correspond to the following classes:\n",
        "# 0\t   Fill\n",
        "# 64\t   Cloud Shadow\n",
        "# 128\t   Clear\n",
        "# 192\t   Thin Cloud\n",
        "# 255\t   Cloud\n",
        "\n",
        "#### READ IMAGE & MASK TO DATASET ####\n",
        "@tf.function\n",
        "def read_img_and_mask(files):\n",
        "    # read img at specified path\n",
        "    r, g, b, mask = files[0], files[1], files[2], files[3]\n",
        "    r, g, b, mask = map(\n",
        "        lambda x: tfio.experimental.image.decode_tiff(tf.io.read_file(x))[:, :, 0], \n",
        "        [r, g, b, mask])\n",
        "    img = tf.experimental.numpy.dstack((r, g, b))\n",
        "\n",
        "    thin_cloud = tf.where(mask == 192, True, False)\n",
        "    cloud = tf.where(mask == 255, True, False)\n",
        "    mask = tf.math.logical_or(thin_cloud, cloud)\n",
        "\n",
        "    return img, mask\n",
        "\n",
        "ds = ds.map(read_img_and_mask, **parallelize)\n",
        "CARDINALITY = ds.cardinality()"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFL3wo9zN6bD"
      },
      "source": [
        "# take n random crops of size h, w from an image and its mask \n",
        "@tf.function\n",
        "def sample_crop(img, mask, h, w, n):\n",
        "  # stack mask and image s.t. we crop both at the same time\n",
        "  img_and_mask = tf.experimental.numpy.dstack((img, mask))\n",
        "  crops = [tf.image.random_crop(img_and_mask, (h, w, 4)) for i in range(n)]\n",
        "  # convert the n stacked, cropped images into a dataset\n",
        "  crops = tf.stack(crops)\n",
        "  crops = tf.data.Dataset.from_tensor_slices(crops)\n",
        "  return crops"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QX2p1tZ287"
      },
      "source": [
        "# randomly crop each img (and its mask) several times\n",
        "# the result of calling this func on every row will return a new dataset\n",
        "# that is n times the original cardinality\n",
        "n, h, w, c = 20, 128, 128, 3\n",
        "ds = ds.interleave(lambda img, mask: sample_crop(img, mask, h, w, n), **parallelize)\n",
        "\n",
        "# tf doesn't know cardinality after interleave, so we help it out\n",
        "CARDINALITY *= n\n",
        "ds = ds.apply(tf.data.experimental.assert_cardinality(CARDINALITY))"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2K983q_pLXR"
      },
      "source": [
        "# represent as tuple of img, mask rather than mask on image\n",
        "# first three layers are the image, fourth layer is the mask\n",
        "ds = ds.map(lambda x: (x[:, :, 0:3], x[:, :, 3]), **parallelize)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es_E-fl6PRqb"
      },
      "source": [
        "# UNET ARCHITECTURE\n",
        "# see original UNET paper here: https://arxiv.org/abs/1505.04597\n",
        "# contact yash if you have questions about UNET\n",
        "# TODO: maybe we could make this simpler while retaining most of the accuracy\n",
        "\n",
        "# Build the model\n",
        "inputs = layers.Input((h, w, c))\n",
        "s = preprocessing.Rescaling(1.0 / 255)(inputs)\n",
        "\n",
        "# Contraction path\n",
        "c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(s)\n",
        "c1 = layers.Dropout(0.1)(c1)\n",
        "c1 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c1)\n",
        "p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n",
        "c2 = layers.Dropout(0.1)(c2)\n",
        "c2 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c2)\n",
        "p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        " \n",
        "c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n",
        "c3 = layers.Dropout(0.2)(c3)\n",
        "c3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c3)\n",
        "p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n",
        "c4 = layers.Dropout(0.2)(c4)\n",
        "c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
        "p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p4)\n",
        "c5 = layers.Dropout(0.3)(c5)\n",
        "c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "#Expansive path \n",
        "u6 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = layers.concatenate([u6, c4])\n",
        "c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
        "c6 = layers.Dropout(0.2)(c6)\n",
        "c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
        " \n",
        "u7 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = layers.concatenate([u7, c3])\n",
        "c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
        "c7 = layers.Dropout(0.2)(c7)\n",
        "c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
        " \n",
        "u8 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = layers.concatenate([u8, c2])\n",
        "c8 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u8)\n",
        "c8 = layers.Dropout(0.1)(c8)\n",
        "c8 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c8)\n",
        " \n",
        "u9 = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = layers.concatenate([u9, c1], axis=3)\n",
        "c9 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(u9)\n",
        "c9 = layers.Dropout(0.1)(c9)\n",
        "c9 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(c9)\n",
        " \n",
        "outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        " \n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOqZRQZRqvnb"
      },
      "source": [
        "# TODO: make a proper validation split\n",
        "\n",
        "# 80-20 train-test split\n",
        "BATCH_SIZE = 32\n",
        "ds = ds.shuffle(buffer_size=CARDINALITY)\n",
        "test_ds = ds.take(CARDINALITY // 5).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "train_ds = ds.skip(CARDINALITY // 5).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFcW0UrjPq4B"
      },
      "source": [
        "# once the val loss stops improving, stop and save \n",
        "# the best model we have created so far\n",
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    restore_best_weights=True,\n",
        "    patience=5\n",
        ")\n",
        "\n",
        "# TODO: change validation_data to valid_ds\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=test_ds,\n",
        "  epochs=50,\n",
        "  callbacks=[callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLyTup5hRp5R"
      },
      "source": [
        "model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}